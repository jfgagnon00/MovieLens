{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a82a80c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-05T16:11:13.284329Z",
     "start_time": "2023-08-05T16:11:13.280194Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- definir quelques styles custom pour l'ensemble du notebook -->\n",
       "<style>    \n",
       "    @import url(\"css/custom_styles.css\")\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!-- definir quelques styles custom pour l'ensemble du notebook -->\n",
    "<style>    \n",
    "    @import url(\"css/custom_styles.css\")\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bafcf8",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>\n",
    "    Transformation Et Manipulation Des Données<br>\n",
    "    </h1>\n",
    "    MovieLens - Préparation des données pour système de recommendations de films.<br>\n",
    "    <br>\n",
    "    <b>Jean-Francois Gagnon</b><br>\n",
    "    <b>Michèle de La Sablonnière</b><br>\n",
    "    <br>\n",
    "    420-A56<br>\n",
    "    <br>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcd3a60",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "    \n",
    "Nous avons choisi la base de données [MovieLens Small](https://tinyurl.com/bdhmcfht). Elle décrit les notations des utilisateurs de MovieLens; un service de recommendation de films. Elle contient plus de 100K notations représentant plus de 9700 films. Ces notations ont été établit par plus de 600 utilisateurs entre mars 1996 et septembre 2018. Elle contient également les métadonnées sur 19 genres. Les données sont structurées dans 4 fichiers distincts.\n",
    "\n",
    "<br>**tags.csv**\n",
    "\n",
    "Fichier contenant les tags (quelques mots générés par les utilisateurs) de chaque film. Ces données ne sont pas utilisées dans ce projet dans un but de réduire la portée.\n",
    "\n",
    "<br>**links.csv**\n",
    "\n",
    "Fichier contenant les metadonnées permettant de lier un film à d'autres source de données. Chaque ligne a ce format:\n",
    "\n",
    "<div class=\"indentation\">\n",
    "<div class=\"fixblock\">movieId, imdbId, tmdbId</div>\n",
    "\n",
    "|Attribut|<center>Description</center>|\n",
    "|:-|:---|\n",
    "|movieId| Identifiant du film dans cette base de données.|\n",
    "|imdbId| Identifiant du film dans [Internet Movie Database](http://www.imdb.com).|\n",
    "|tmdbId| Identifiant du film dans [The Movie DB](https://www.themoviedb.org).|    \n",
    "</div>\n",
    "\n",
    "<br>**ratings.csv**\n",
    "\n",
    "Ce fichier contient les notations. Chaque ligne a ce format:\n",
    "\n",
    "<div class=\"indentation\">\n",
    "<div class=\"fixblock\">userId, movieId, rating, timestamp</div>\n",
    "\n",
    "|Attribut|<center>Description</center>|\n",
    "|:-|:---|\n",
    "|userId| Identifiant de l'utilisateur dans cette base de données.|\n",
    "|movieId| Identifiant du film dans cette base de données.|\n",
    "|rating| Nombre d'étoiles attribuées avec une granularité de $\\frac{1}{2}$. |\n",
    "|timestamp| Date à laquelle la note a été entré. Encodée dans le format [UTC](https://tinyurl.com/32e6a5pc).|\n",
    "</div>\n",
    "\n",
    "<br>**movies.csv**\n",
    "\n",
    "Ce fichier contient les métadonnées de chaque film. Chaque ligne a ce format:\n",
    "\n",
    "<div class=\"indentation\">\n",
    "<div class=\"fixblock\">movieId, title, genres</div>\n",
    "\n",
    "|Attribut|<center>Description</center>|\n",
    "|:-|:---|\n",
    "|userId| Identifiant de l'utilisateur dans cette base de données.|\n",
    "|movieId| Identifiant du film dans cette base de données.|\n",
    "|rating| Nombre d'étoiles attribuées avec une granularité de $\\frac{1}{2}$. |\n",
    "|timestamp| Date à laquelle la note a été entré. Encodée dans le format [UTC](https://tinyurl.com/32e6a5pc).|\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "L'objectif de ce projet est de préparer les données pour un éventuel système de recommentation de films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d914ec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:24.173183Z",
     "start_time": "2023-08-02T22:14:19.116329Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# imports utilitaires\n",
    "#\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#\n",
    "# imports faisant partie de mes propres module\n",
    "#\n",
    "\n",
    "import helpers as hlp\n",
    "import helpers.Clustering as clstr\n",
    "import helpers.dataset.MovieLens as mvl\n",
    "import helpers.WebScraping as scrap\n",
    "import helpers.jupyter as jup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec93b72",
   "metadata": {},
   "source": [
    "# Prétraitement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682de01b",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "\n",
    "Description ici?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654c4385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:24.250343Z",
     "start_time": "2023-08-02T22:14:24.175343Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# parametres configurant nos traitemens\n",
    "#\n",
    "configs = hlp.get_configs(\"config_overrides.json\")\n",
    "\n",
    "#\n",
    "# obtenir le dataset\n",
    "#\n",
    "mvl_dataset = mvl.load(configs.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5118517",
   "metadata": {},
   "source": [
    "## links.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd4ee44",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "    \n",
    "links.csv n'est pas utilisé directement pour le clustering. Cependant, il le sera pour complémenter l'information des autres base de données. Il m'apparait donc imporant de faire un survol rapide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf550da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:24.271863Z",
     "start_time": "2023-08-02T22:14:24.252462Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Links\", mvl_dataset.links.shape)\n",
    "print(\"Head\")\n",
    "display(mvl_dataset.links.head())\n",
    "clstr.show_na(mvl_dataset.links)\n",
    "clstr.show_types(mvl_dataset.links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8014dc1d",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "    \n",
    "Il manque quelques liens sur [TMDB](https://www.themoviedb.org/) (ce qui explique le type float64). Les liens [IMDB](https://www.imdb.com/) seront par conséquent utilisés pour fin de web scrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b174c52",
   "metadata": {},
   "source": [
    "## movies.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1978af6",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "    \n",
    "Mettre description ici?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719fc69a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:24.288296Z",
     "start_time": "2023-08-02T22:14:24.275297Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Movies\", mvl_dataset.movies.shape)\n",
    "print(\"Head\")\n",
    "display(mvl_dataset.movies.head())\n",
    "clstr.show_na(mvl_dataset.movies)\n",
    "clstr.show_types(mvl_dataset.movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8245cf58",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "\n",
    "Tel que décris par MovieLens, *title* contient l'année de parution. Nous allons l'extraire afin d'obtenir une nouvelle variable. *title* sera adressé un pleu plus bas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e568fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:25.922409Z",
     "start_time": "2023-08-02T22:14:24.289797Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def split_title_year(title, regex):\n",
    "    x = regex.search(title)\n",
    "    if x:\n",
    "        title = x.group(1)\n",
    "        year = x.group(2)\n",
    "        year = int(year) if year else pd.NA\n",
    "    else:\n",
    "        year = pd.NA\n",
    "    \n",
    "    return pd.Series({\"title\": title, \"year\": year})\n",
    "\n",
    "title_year_re = re.compile(configs.dataset.title_regex, flags=0)        \n",
    "title_year = mvl_dataset.movies.title.apply(split_title_year, args=(title_year_re,))\n",
    "\n",
    "#\n",
    "# validation de l'extraction\n",
    "#\n",
    "print(\"Informations extraites\", title_year.shape)\n",
    "print(\"Head\")\n",
    "display(title_year.head())\n",
    "clstr.show_na(title_year)\n",
    "clstr.show_types(title_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b581c8",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "   \n",
    "On peut remarquer qu'il manque quelques années de parution. Il est probablement possible de les fixer en utilisant *links.imdbId* avec le web scrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3a9fa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:28.271538Z",
     "start_time": "2023-08-02T22:14:25.924435Z"
    },
    "code_folding": [
     0,
     30
    ]
   },
   "outputs": [],
   "source": [
    "def imdb_scap_year(response, index, imdbId):\n",
    "    success = False\n",
    "    if response.ok:\n",
    "        bs = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        imdb_info = bs.find(\"script\", attrs={\"type\": \"application/ld+json\"})\n",
    "        imdb_json = json.loads(imdb_info.text)\n",
    "        date_published = scrap.get_nested_property(imdb_json, [\"datePublished\"])\n",
    "        if not success and date_published:\n",
    "            date_published = pd.to_datetime(date_published)\n",
    "            year = date_published.year\n",
    "            success = True\n",
    "\n",
    "        imdb_info = bs.find(\"script\", attrs={\"type\": \"application/json\"})\n",
    "        imdb_json = json.loads(imdb_info.text)\n",
    "        releaseYear = scrap.get_nested_property(imdb_json, \n",
    "                                                [\"props\", \n",
    "                                                 \"pageProps\", \n",
    "                                                 \"mainColumnData\", \n",
    "                                                 \"releaseYear\",\n",
    "                                                 \"year\"])\n",
    "        if not success and releaseYear:\n",
    "            year = releaseYear\n",
    "            success = True\n",
    "\n",
    "    if success:\n",
    "        return (index, year, response.url)\n",
    "    else:\n",
    "        return (index, None, response.url)\n",
    "\n",
    "def imdb_scap_year_apply_results(final_results):\n",
    "    for index, year, url in final_results:\n",
    "        if year is None:\n",
    "            print(url, title_year.title[index], \"Failed\")\n",
    "        else:\n",
    "            title_year.year[index] = year\n",
    "\n",
    "#    \n",
    "# corriger year via web scrapping avec imdb\n",
    "#\n",
    "year_na = title_year.year.isna()\n",
    "year_link = mvl_dataset.links.imdbId[ year_na ]\n",
    "\n",
    "if year_link.shape[0] > 0:\n",
    "    with hlp.Profile() as year_profile:\n",
    "        results = scrap.imdb_requests_parallel(year_link,\n",
    "                                               configs.web_scraping,\n",
    "                                               imdb_scap_year,\n",
    "                                               executor=configs.executor)\n",
    "        imdb_scap_year_apply_results(results)\n",
    "    print(f\"Web scraping year: {year_profile.round_duration(2)}s\")\n",
    "\n",
    "# validation du scapping\n",
    "clstr.show_na(title_year);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c90c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:28.277199Z",
     "start_time": "2023-08-02T22:14:28.273468Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# mettre a jour movies\n",
    "#\n",
    "mvl_dataset.movies[\"year\"] = title_year.year.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f934ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:31.618230Z",
     "start_time": "2023-08-02T22:14:28.279516Z"
    },
    "code_folding": [
     9
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "# validation effet extraction de l'annee de title\n",
    "#\n",
    "imdb_ids = mvl_dataset.links.imdbId[mvl_dataset.links.movieId == mvl_dataset.movies.movieId]\n",
    "\n",
    "title = mvl_dataset.movies[[\"movieId\", \"year\"]].copy()\n",
    "title[\"title\"] = title_year.title.copy()\n",
    "title[\"imdbId\"] = imdb_ids.copy()\n",
    "\n",
    "def title_agregate(dataframe):\n",
    "    return pd.Series({\"imdbIds\": dataframe.imdbId.unique(),\n",
    "                      \"years\": dataframe.year.unique(),\n",
    "                      \"counts\": dataframe.movieId.nunique()})\n",
    "\n",
    "groups = title.groupby(\"title\").apply(title_agregate)\n",
    "groups.sort_values(by=\"counts\", ascending=False, inplace=True)\n",
    "\n",
    "display(groups.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea018a4",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "    \n",
    "Une inspection manuelle de [Hamlet 1996](http://www.imdb.com/title/tt0116477) et [Hamlet 1948](http://www.imdb.com/title/tt0040416) via IMDB permet de voir que l'année juxtaposée au titre est un identifiant unique. Je dois donc garder *title* original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2123f163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:31.627572Z",
     "start_time": "2023-08-02T22:14:31.620126Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# validation doublons\n",
    "#\n",
    "print(\"Vérifier doublons\")\n",
    "print(\"Avant:\", mvl_dataset.movies.shape)\n",
    "mvl_dataset.movies.drop_duplicates(inplace=True)\n",
    "print(\"Après:\", mvl_dataset.movies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c5ed4b",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "Aucun doublon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695dfa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:31.655396Z",
     "start_time": "2023-08-02T22:14:31.635827Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "# validation modalites genres\n",
    "#\n",
    "def show_unique_genres(sort_effectif=False):\n",
    "    genres_count = {}\n",
    "\n",
    "    def add(genre):\n",
    "        if genre in genres_count:\n",
    "            genres_count[genre] += 1\n",
    "        else:\n",
    "            genres_count[genre] = 1\n",
    "    \n",
    "    for genres_str in mvl_dataset.movies.genres:\n",
    "        if genres_str is None:\n",
    "            add(None)\n",
    "        else:\n",
    "            genre_array = genres_str.split(configs.dataset.genre_splitter)\n",
    "            for genre in genre_array:\n",
    "                add(genre)\n",
    "\n",
    "    genres_df = pd.Series(data=genres_count.values(),\n",
    "                          index=genres_count.keys(),\n",
    "                          name=\"# films\")\n",
    "\n",
    "    if sort_effectif:\n",
    "        #genres_df /= mvl_dataset.movies.shape[0] / 100\n",
    "        genres_df.sort_values(ascending=False, inplace=True)\n",
    "    else:\n",
    "        genres_df.sort_index(inplace=True)\n",
    "\n",
    "    print(\"Unique genres:\", genres_df.shape[0])\n",
    "    display(genres_df.to_frame())\n",
    "\n",
    "show_unique_genres()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c8962",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T00:35:29.008411Z",
     "start_time": "2023-07-17T00:35:29.005017Z"
    }
   },
   "source": [
    "<font class=\"answer\">\n",
    "\n",
    "(no genres listed) semble être en fait des valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366e6826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:31.669925Z",
     "start_time": "2023-08-02T22:14:31.657371Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "# examiner (no genres listed)\n",
    "#    \n",
    "def show_no_genres():\n",
    "    no_genres_crit = mvl_dataset.movies.genres.str.contains(\"(no genres listed)\", regex=False)\n",
    "    no_genres = mvl_dataset.movies[no_genres_crit]\n",
    "    print(\"(no genres listed)\", no_genres.shape[0])\n",
    "    if no_genres.shape[0] > 0:\n",
    "        display(no_genres.head())\n",
    "    return no_genres.index\n",
    "    \n",
    "no_genres_index = show_no_genres()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6165c1",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "Je vais utiliser le web scrapping pour tenter de remplacer (no genres listed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f311dea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:37.694967Z",
     "start_time": "2023-08-02T22:14:31.671943Z"
    },
    "code_folding": [
     0,
     22,
     40
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def imdb_scap_genres(response, index, imdbId):\n",
    "    success = False\n",
    "    if response.ok:\n",
    "        bs = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        imdb_info = bs.find(\"script\", attrs={\"type\": \"application/ld+json\"})\n",
    "        imdb_json = json.loads(imdb_info.text)\n",
    "                \n",
    "        genres = scrap.get_nested_property(imdb_json, [\"genre\"])\n",
    "        if not success and genres:\n",
    "            success = True\n",
    "        else:\n",
    "            error = json.dumps(imdb_json, indent=4)\n",
    "    else:\n",
    "        error = response.reason\n",
    "\n",
    "    if success:\n",
    "        return (index, genres, response.url, None)\n",
    "    else:\n",
    "        \n",
    "        return (index, None, response.url, error)\n",
    "\n",
    "def imdb_scap_genres_apply_results(final_results, genres_splitter):\n",
    "    for index, genres, url, error in final_results:\n",
    "        if genres is None:\n",
    "            if False:\n",
    "                print()\n",
    "                print(error)\n",
    "                print()\n",
    "\n",
    "            print(url, mvl_dataset.movies.title[index], \"Failed\")\n",
    "        else:\n",
    "            mvl_dataset.movies.loc[index, \"genres\"] = genres_splitter.join(genres)\n",
    "\n",
    "\n",
    "#\n",
    "# corriger genres via web scrapping avec imdb\n",
    "#\n",
    "genres_imdbIds = mvl_dataset.links.imdbId[no_genres_index]\n",
    "\n",
    "if genres_imdbIds.shape[0] > 0:\n",
    "    with hlp.Profile() as genres_profile:\n",
    "        if True:\n",
    "            results = scrap.imdb_requests_parallel(genres_imdbIds, \n",
    "                                                   configs.web_scraping, \n",
    "                                                   imdb_scap_genres,\n",
    "                                                   executor=configs.executor)\n",
    "            imdb_scap_genres_apply_results(results, configs.dataset.genre_splitter)\n",
    "        else:\n",
    "            # les resultats ne sont pas appliques ici\n",
    "            # ce code n'existe que pour mesurer le gain du multithreading\n",
    "            scrap.imdb_requests(genres_imdbIds, \n",
    "                                configs.web_scraping, \n",
    "                                imdb_scap_genres)\n",
    "    print(f\"Web scraping genres: {genres_profile.round_duration(2)}s\")\n",
    "        \n",
    "show_unique_genres(sort_effectif=True)\n",
    "show_no_genres();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97846735",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "    \n",
    "Par souci de réduire la quantité de modalités, toutes celles en dessous de 4 individus seront enlevées. Noter que Music et Musical sont synonyme. Finalement, IMAX n'est pas un genre mais bien un format de diffusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a60f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:37.721443Z",
     "start_time": "2023-08-02T22:14:37.697353Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def clean_genres(genres_str, splitter, to_remove):\n",
    "    if genres_str is None or not isinstance(genres_str, str):\n",
    "        return genres_str\n",
    "    \n",
    "    genres_list = genres_str.split(splitter)\n",
    "    genres_set = set(genres_list)\n",
    "    genres_set -= to_remove\n",
    "    \n",
    "    # bien que non portable, par souci d'efficacite\n",
    "    # handler Music et Musical\n",
    "    if \"Music\" in genres_set:\n",
    "        genres_set.remove(\"Music\")\n",
    "        genres_set.add(\"Musical\")\n",
    "\n",
    "    genres_str = splitter.join(genres_set)\n",
    "    if len(genres_str) == 0:\n",
    "        genres_str = None\n",
    "\n",
    "    return genres_str\n",
    "\n",
    "\n",
    "#\n",
    "# nettoyer les modalites de genres\n",
    "#\n",
    "to_remove = [\"IMAX\", \"Short\", \"Biography\", \"Family\", \"History\"]\n",
    "to_remove = set(to_remove)\n",
    "cleaned_genres = mvl_dataset.movies.genres.apply(clean_genres, \n",
    "                                                 splitter=configs.dataset.genre_splitter,\n",
    "                                                 to_remove=to_remove)\n",
    "mvl_dataset.movies[\"genres\"] = cleaned_genres\n",
    "\n",
    "print(\"Genres nettoyés\")\n",
    "genres_na = clstr.show_na(mvl_dataset.movies)\n",
    "print(mvl_dataset.movies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab43f49",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "Certains films avaient 1 seul genre. Après le retrait précédant, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7557b40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:37.746234Z",
     "start_time": "2023-08-02T22:14:37.723471Z"
    }
   },
   "outputs": [],
   "source": [
    "mvl_dataset.movies.drop(index=genres_na, axis=0, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# validation retrain NA de genres\n",
    "show_unique_genres(sort_effectif=True)\n",
    "clstr.show_na(mvl_dataset.movies);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5261b409",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "\n",
    "Afin de simplifier la partie exploration, je vais ajouter *imdbId* à *movies.csv* afin d'avoir l'information dans une seule base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a6c022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:37.764791Z",
     "start_time": "2023-08-02T22:14:37.748343Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# ajout imdbId a movies\n",
    "#\n",
    "mvl_dataset.movies = pd.merge(mvl_dataset.movies, \n",
    "                              mvl_dataset.links[[\"movieId\", \"imdbId\"]],\n",
    "                              how=\"left\", \n",
    "                              on=\"movieId\")\n",
    "\n",
    "# pour faciliter la visualization, mettre immediatement imdbId\n",
    "mvl_dataset.movies.insert(1, 'imdbId', mvl_dataset.movies.pop('imdbId'))\n",
    "\n",
    "# validation\n",
    "print(\"Validation ajout imdbId\")\n",
    "display(mvl_dataset.movies.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0ee94f",
   "metadata": {},
   "source": [
    "## ratings.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2a120d",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "    \n",
    "Mettre description ici?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fade49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:37.783475Z",
     "start_time": "2023-08-02T22:14:37.767457Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Ratings\", mvl_dataset.ratings.shape)\n",
    "print(\"Head\")\n",
    "display(mvl_dataset.ratings.head())\n",
    "clstr.show_na(mvl_dataset.ratings)\n",
    "clstr.show_types(mvl_dataset.ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f8ac4",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "  \n",
    "*rating*, bien que montré en nombre flottant, est en fait un système d'étoiles ou la mesure de base est$\\frac{1}{2}$. Je garde en quantitatif pour le moment car il semble avantageux pour faire un lien avec les données dans *movies.csv*. L'exploration pourra décider s'il est pertinant de passer en catégoriel si on traite les *ratings.csv* à part (système de recommendation collaboratif).\n",
    "    \n",
    "*timestamp* est en fait une date dans le format UTC. Ceci semble suggérer qu'un utilisateur peut avoir voté plus d'une fois pour le même film ou utiliser un système pour automatisé pour biaser les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7690fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:37.814567Z",
     "start_time": "2023-08-02T22:14:37.785359Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# verification nombre de votes par couple (utilisateur, film)\n",
    "#\n",
    "votes = mvl_dataset.ratings.groupby(by=[\"userId\", \"movieId\"]).size().max()\n",
    "print(\"Nombre de votes par (userId, movieId):\", votes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f44236",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "Un seul vote par utilisateur par film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bf4155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:38.090620Z",
     "start_time": "2023-08-02T22:14:37.817042Z"
    },
    "code_folding": [
     3,
     6,
     29
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "# verification frequence des votes par utilisateur\n",
    "#\n",
    "def dt_sec(data):\n",
    "    return data.max() - data.min()\n",
    "\n",
    "def dt_expanded(data):\n",
    "    utc_min = datetime.utcfromtimestamp(data.min())\n",
    "    utc_max = datetime.utcfromtimestamp(data.max())\n",
    "    dt_full = relativedelta(utc_max, utc_min)\n",
    "    \n",
    "    full = []\n",
    "    if dt_full.years > 0:\n",
    "        full.append(f\"{dt_full.years}y\")\n",
    "    elif dt_full.months > 0:\n",
    "        full.append(f\"{dt_full.months}m\")\n",
    "    elif dt_full.days > 0:\n",
    "        full.append(f\"{dt_full.days}d\")\n",
    "    elif dt_full.hours > 0:\n",
    "        full.append(f\"{dt_full.hours}h\")\n",
    "    else:\n",
    "        if dt_full.minutes > 0:\n",
    "            full.append(f\"{dt_full.minutes}m\")\n",
    "\n",
    "        if dt_full.seconds > 0:\n",
    "            full.append(f\"{dt_full.seconds}s\")\n",
    "    \n",
    "    return \" \".join(full)\n",
    "\n",
    "def rating_freq(data):\n",
    "    num = data.shape[0]\n",
    "    freq = num / dt_sec(data)\n",
    "    # mHz pour mieux voir ecarts\n",
    "    return freq * 1000\n",
    "\n",
    "user_ratings = mvl_dataset.ratings[[\"userId\", \"rating\", \"timestamp\"]] \\\n",
    "                          .groupby(by=\"userId\") \\\n",
    "                          .agg(rating_count=(\"rating\", \"count\"), \n",
    "                               dt_sec=(\"timestamp\", dt_sec),\n",
    "                               dt_expanded=(\"timestamp\", dt_expanded),\n",
    "                               rating_freq=(\"timestamp\", rating_freq))\n",
    "\n",
    "rating_freq_stats = user_ratings.rating_freq.describe().to_frame()\n",
    "rating_cout_stats = user_ratings.rating_count.describe().to_frame()\n",
    "fastest_users = user_ratings.nlargest(5, \"rating_freq\")\n",
    "slowest_users = user_ratings.nsmallest(5, \"rating_freq\")\n",
    "\n",
    "html = jup.horizontify(jup.caption_df(fastest_users.style, \"User les plus rapide\", caption_bold=False), \n",
    "                       jup.caption_df(slowest_users.style, \"User les moins rapide\", caption_bold=False))\n",
    "jup.display_html(html)\n",
    "\n",
    "print()\n",
    "print(\"Stats générale\")\n",
    "html = jup.horizontify(rating_freq_stats.style, rating_cout_stats.style)\n",
    "jup.display_html(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b38e4d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:38.401083Z",
     "start_time": "2023-08-02T22:14:38.092752Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "# visualiser rating_count vs rating_freq\n",
    "#\n",
    "def rating_count_vs_freq(user_ratings, critOutliers=None, figsize=(7, 3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    if critOutliers is None:\n",
    "        plt.scatter(user_ratings.rating_count, user_ratings.rating_freq, s=5)\n",
    "    else:\n",
    "        outliers = user_ratings[critOutliers]\n",
    "        plt.scatter(outliers.rating_count, outliers.rating_freq, s=5, label=\"Outliers\")\n",
    "        \n",
    "        inliers = user_ratings[~critOutliers]\n",
    "        plt.scatter(inliers.rating_count, inliers.rating_freq, s=5, label=\"Inliers\")\n",
    "        \n",
    "        plt.legend()\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"Rating Count\")\n",
    "    plt.ylabel(\"Rating Freq (mHz)\")\n",
    "    plt.show()\n",
    "    \n",
    "rating_count_vs_freq(user_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36fec80",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "Les utilisateurs ont votés relativement souvent (20 votes ou plus) mais la distribution est très allongée et fortement concentrée dans les valeurs faible. Le graphe ci-haut suggère que les votes semblent avoir étés fait de façon très rapide. Pour illustrer, le user *163* aurait voté 23 fois en 38 secondes (~2 secondes par vote). mais le user *172* aurait pris 1 an pour ses 26 votes. Faute d'information supplémentaire, je suspecte un système automatisé et enlève les utilisateurs ayant une fréquence de vote jugée trop élevée.<br><br>\n",
    "    \n",
    "En absolue:\n",
    "$$\n",
    "\\begin{align}\n",
    "threshold &= Q_3 + 1.5 * IQR\\\\\n",
    "          &= 62.19 + 1.5 * (62.19 - 0.04)\\\\\n",
    "          &= 155.36\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "  \n",
    "Une approche basée sur le clustering, plus particulièrement DBSCAN, trouvera les éléments isolés dans le graphe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0222995",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:42.298690Z",
     "start_time": "2023-08-02T22:14:38.402591Z"
    }
   },
   "outputs": [],
   "source": [
    "coords = RobustScaler().fit_transform(user_ratings[[\"rating_count\", \"rating_freq\"]])\n",
    "clstr.dbscan_eps_analysis(coords, figsize=(6, 3.5))\n",
    "\n",
    "eps_, min_samples_ = clstr.dbscan_parameters_analysis(coords, \n",
    "                                                      np.arange(0.25, 0.45, 0.01),\n",
    "                                                      range(2, 20))\n",
    "dbscan_ = clstr.dbscan_init(coords, eps_, min_samples_)\n",
    "clstr.show_clusters(coords, \n",
    "                    user_ratings.index, \n",
    "                    dbscan_.labels_, \n",
    "                    figsize=(7, 3.5),\n",
    "                    text_alpha=0, \n",
    "                    marker_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7537e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:42.455683Z",
     "start_time": "2023-08-02T22:14:42.300884Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# detecter les user juges outliers\n",
    "#\n",
    "critA = dbscan_.labels_ == -1\n",
    "\n",
    "# dbscan marque certaines basses frequences \n",
    "# s'assurer de les garder\n",
    "critB = user_ratings.rating_freq > 1\n",
    "\n",
    "# IQR threshold\n",
    "critC = user_ratings.rating_freq >= 155.36\n",
    "\n",
    "# combiner tous les criteres d'outliers\n",
    "critOutliers = critA & critB | critC\n",
    "\n",
    "print(\"Nombre de user outliers\", np.count_nonzero(critOutliers))\n",
    "rating_count_vs_freq(user_ratings, critOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a185928d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:42.465231Z",
     "start_time": "2023-08-02T22:14:42.457254Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# enlever les user juges outliers\n",
    "#\n",
    "user_to_remove = user_ratings[critOutliers].index.to_list()\n",
    "user_to_remove = mvl_dataset.ratings.userId.isin(user_to_remove)\n",
    "user_to_remove = mvl_dataset.ratings[user_to_remove]\n",
    "\n",
    "print(\"ratings avant retrait users:\", mvl_dataset.ratings.shape[0])\n",
    "mvl_dataset.ratings.drop(user_to_remove.index, inplace=True, errors=\"ignore\")\n",
    "print(\"ratings après retrait users:\", mvl_dataset.ratings.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deddb6a",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "Pour movies.csv, il apparait judicieux d'extraire quelques statistiques sur *rating*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce4615",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:46.111954Z",
     "start_time": "2023-08-02T22:14:42.467261Z"
    },
    "code_folding": [
     0,
     3,
     6,
     10,
     14
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def etendue(ratings):\n",
    "    return ratings.max() - ratings.min()\n",
    "\n",
    "def iqr(ratings):\n",
    "    return ratings.quantile(0.75) - ratings.quantile(0.25)\n",
    "\n",
    "def mode(ratings):\n",
    "    # prendre le mode le plus grand\n",
    "    return ratings.mode().iloc[-1]\n",
    "\n",
    "def median_keep_category(ratings):\n",
    "    # garder les modalites de ratings si nombre de valeurs est impaire\n",
    "    return ratings.quantile(interpolation=\"nearest\")\n",
    "\n",
    "def join_name(multi_index_name):\n",
    "    if \"\" in multi_index_name:\n",
    "        return multi_index_name[0]\n",
    "    else:\n",
    "        return \"_\".join(multi_index_name)\n",
    "\n",
    "\n",
    "#\n",
    "# creer des variables pour movies\n",
    "#\n",
    "ratings_stats = mvl_dataset.ratings[[\"movieId\", \"rating\"]] \\\n",
    "                           .groupby(by=\"movieId\") \\\n",
    "                           .agg([\"count\", (\"mode\", mode), \"mean\", (\"median\", median_keep_category)])\n",
    "ratings_stats.columns = [join_name(a) for a in ratings_stats.columns.to_flat_index()]\n",
    "ratings_stats.reset_index(inplace=True)\n",
    "print(\"Rating stats\", ratings_stats.shape)\n",
    "print(\"Head\")\n",
    "display(ratings_stats.head().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3397ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:46.118010Z",
     "start_time": "2023-08-02T22:14:46.113476Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# detailler les valeurs manquantes\n",
    "#\n",
    "clstr.show_na(ratings_stats);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85163f04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:46.142528Z",
     "start_time": "2023-08-02T22:14:46.119930Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# valider que ratings_stats contient bien les meme films que movies.csv\n",
    "#\n",
    "movies_ratings = pd.merge(mvl_dataset.movies, ratings_stats, how=\"left\", on=\"movieId\")\n",
    "movies_ratings_na = clstr.show_na(movies_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ffc7b",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "    \n",
    "Tous les films n'ont pas reçu de votes. Je pourrais utiliser le web scraping pour remplir rating_mean mais l'echelle sur IMDB n'est pas la même que MovieLens. De plus les autres statistiques ne pourraient pas être extraite. Comme il n'y a que très peux d'éléments manquants je vais les ignorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55513c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:46.157871Z",
     "start_time": "2023-08-02T22:14:46.144712Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# enlever valeurs manquantes et valider shape resultante\n",
    "#\n",
    "print(\"movies_ratings avant retrait:\", movies_ratings.shape)\n",
    "movies_ratings.drop(index=movies_ratings_na, axis=0, inplace=True, errors=\"ignore\")\n",
    "print(\"movies_ratings après retrait:\", movies_ratings.shape)\n",
    "print()\n",
    "#\n",
    "# valider les types (drop() peut changer les choses du aux NA)\n",
    "#\n",
    "clstr.show_types(movies_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d309cea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:46.164112Z",
     "start_time": "2023-08-02T22:14:46.160092Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# rating_count est en fait un entier, changer son type\n",
    "#\n",
    "movies_ratings.rating_count = movies_ratings.rating_count.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d225cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:46.234373Z",
     "start_time": "2023-08-02T22:14:46.176025Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# sauvegarde des traitements sur movies_ratings\n",
    "#\n",
    "csv_path = mvl_dataset.movies_path.split(\".\")[0]\n",
    "csv_path = \"\".join([csv_path, \"_pretraitement\", \".csv\"])\n",
    "\n",
    "print(\"Sauvegarde\", csv_path)\n",
    "movies_ratings.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f6f135",
   "metadata": {},
   "source": [
    "## Collaborative filtering<br>\n",
    "<font class=\"answer\">\n",
    "Les systèmes de votes ont souvent 2 composantes: content base et collaborative filtering. L'idée étant d'utiliser l'historique d'un utilisateur (collaborative filtering) et à défaut de l'avoir, utiliser seulement le contenu des fims. Notre base de donnée est plutot simple, nous auront donc seulement rating pour regrouper les users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f268d13b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:46.315788Z",
     "start_time": "2023-08-02T22:14:46.235977Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# s'assurer de garder uniquement les uers qui ont les movieId present dans movies_ratings\n",
    "#\n",
    "movieIds = movies_ratings.movieId.unique()\n",
    "ratings = mvl_dataset.ratings[ mvl_dataset.ratings.movieId.isin(movieIds)  ]\n",
    "user_ratings = ratings.pivot(index=\"userId\", columns=\"movieId\", values=\"rating\")\n",
    "\n",
    "display(user_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59363e88",
   "metadata": {},
   "source": [
    "<font class=\"answer\">\n",
    "Données très éparse. Ceci est attendu puisque le système veux faire des suggestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f556d2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T22:14:49.053768Z",
     "start_time": "2023-08-02T22:14:46.318060Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# sauvegarde des traitements sur user_ratings\n",
    "#\n",
    "csv_path = mvl_dataset.ratings_path.split(\".\")[0]\n",
    "csv_path = \"\".join([csv_path, \"_pretraitement\", \".csv\"])\n",
    "\n",
    "print(\"Sauvegarde\", csv_path)\n",
    "user_ratings.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
